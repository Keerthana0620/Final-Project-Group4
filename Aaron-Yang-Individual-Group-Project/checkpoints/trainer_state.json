{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 32902,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0030393289161753084,
      "grad_norm": 2.9053401947021484,
      "learning_rate": 0.0002991246732721415,
      "loss": 3.7115,
      "step": 100
    },
    {
      "epoch": 0.006078657832350617,
      "grad_norm": 2.2920758724212646,
      "learning_rate": 0.0002982128745972889,
      "loss": 3.5454,
      "step": 200
    },
    {
      "epoch": 0.009117986748525925,
      "grad_norm": 2.4281015396118164,
      "learning_rate": 0.00029730107592243634,
      "loss": 3.4907,
      "step": 300
    },
    {
      "epoch": 0.012157315664701233,
      "grad_norm": 2.462831735610962,
      "learning_rate": 0.0002963892772475837,
      "loss": 3.434,
      "step": 400
    },
    {
      "epoch": 0.015196644580876542,
      "grad_norm": 2.4920883178710938,
      "learning_rate": 0.00029547747857273113,
      "loss": 3.3888,
      "step": 500
    },
    {
      "epoch": 0.01823597349705185,
      "grad_norm": 2.418646812438965,
      "learning_rate": 0.00029456567989787855,
      "loss": 3.4419,
      "step": 600
    },
    {
      "epoch": 0.02127530241322716,
      "grad_norm": 2.2071497440338135,
      "learning_rate": 0.0002936538812230259,
      "loss": 3.378,
      "step": 700
    },
    {
      "epoch": 0.024314631329402467,
      "grad_norm": 2.0690205097198486,
      "learning_rate": 0.00029274208254817334,
      "loss": 3.3757,
      "step": 800
    },
    {
      "epoch": 0.027353960245577777,
      "grad_norm": 3.0704667568206787,
      "learning_rate": 0.00029183028387332077,
      "loss": 3.364,
      "step": 900
    },
    {
      "epoch": 0.030393289161753084,
      "grad_norm": 2.0249834060668945,
      "learning_rate": 0.0002909184851984682,
      "loss": 3.3376,
      "step": 1000
    },
    {
      "epoch": 0.03343261807792839,
      "grad_norm": 2.918764352798462,
      "learning_rate": 0.00029000668652361556,
      "loss": 3.3845,
      "step": 1100
    },
    {
      "epoch": 0.0364719469941037,
      "grad_norm": 2.0039896965026855,
      "learning_rate": 0.000289094887848763,
      "loss": 3.3839,
      "step": 1200
    },
    {
      "epoch": 0.03951127591027901,
      "grad_norm": 2.0264527797698975,
      "learning_rate": 0.0002881830891739104,
      "loss": 3.3347,
      "step": 1300
    },
    {
      "epoch": 0.04255060482645432,
      "grad_norm": 2.0624847412109375,
      "learning_rate": 0.0002872712904990578,
      "loss": 3.3317,
      "step": 1400
    },
    {
      "epoch": 0.04558993374262963,
      "grad_norm": 2.158184766769409,
      "learning_rate": 0.0002863594918242052,
      "loss": 3.3093,
      "step": 1500
    },
    {
      "epoch": 0.048629262658804934,
      "grad_norm": 2.525071382522583,
      "learning_rate": 0.0002854476931493526,
      "loss": 3.2995,
      "step": 1600
    },
    {
      "epoch": 0.051668591574980244,
      "grad_norm": 2.636016607284546,
      "learning_rate": 0.0002845358944745,
      "loss": 3.2817,
      "step": 1700
    },
    {
      "epoch": 0.054707920491155554,
      "grad_norm": 1.9637755155563354,
      "learning_rate": 0.0002836240957996474,
      "loss": 3.2665,
      "step": 1800
    },
    {
      "epoch": 0.057747249407330864,
      "grad_norm": 2.0455713272094727,
      "learning_rate": 0.00028271229712479483,
      "loss": 3.2788,
      "step": 1900
    },
    {
      "epoch": 0.06078657832350617,
      "grad_norm": 2.650871515274048,
      "learning_rate": 0.00028180049844994226,
      "loss": 3.2357,
      "step": 2000
    },
    {
      "epoch": 0.06382590723968148,
      "grad_norm": 2.5464158058166504,
      "learning_rate": 0.0002808886997750896,
      "loss": 3.2902,
      "step": 2100
    },
    {
      "epoch": 0.06686523615585678,
      "grad_norm": 2.087799310684204,
      "learning_rate": 0.00027997690110023705,
      "loss": 3.1887,
      "step": 2200
    },
    {
      "epoch": 0.06990456507203209,
      "grad_norm": 1.682326316833496,
      "learning_rate": 0.00027906510242538447,
      "loss": 3.2575,
      "step": 2300
    },
    {
      "epoch": 0.0729438939882074,
      "grad_norm": 2.410738468170166,
      "learning_rate": 0.00027815330375053184,
      "loss": 3.259,
      "step": 2400
    },
    {
      "epoch": 0.07598322290438271,
      "grad_norm": 1.8998686075210571,
      "learning_rate": 0.00027724150507567926,
      "loss": 3.2812,
      "step": 2500
    },
    {
      "epoch": 0.07902255182055802,
      "grad_norm": 2.1132633686065674,
      "learning_rate": 0.0002763297064008267,
      "loss": 3.3174,
      "step": 2600
    },
    {
      "epoch": 0.08206188073673333,
      "grad_norm": 2.384528160095215,
      "learning_rate": 0.0002754179077259741,
      "loss": 3.3015,
      "step": 2700
    },
    {
      "epoch": 0.08510120965290864,
      "grad_norm": 2.3288486003875732,
      "learning_rate": 0.0002745061090511215,
      "loss": 3.4124,
      "step": 2800
    },
    {
      "epoch": 0.08814053856908395,
      "grad_norm": 1.847561001777649,
      "learning_rate": 0.0002735943103762689,
      "loss": 3.1925,
      "step": 2900
    },
    {
      "epoch": 0.09117986748525926,
      "grad_norm": 1.9737703800201416,
      "learning_rate": 0.0002726825117014163,
      "loss": 3.2239,
      "step": 3000
    },
    {
      "epoch": 0.09421919640143456,
      "grad_norm": 1.8790098428726196,
      "learning_rate": 0.0002717707130265637,
      "loss": 3.1997,
      "step": 3100
    },
    {
      "epoch": 0.09725852531760987,
      "grad_norm": 2.1242074966430664,
      "learning_rate": 0.0002708589143517111,
      "loss": 3.2547,
      "step": 3200
    },
    {
      "epoch": 0.10029785423378518,
      "grad_norm": 2.351738691329956,
      "learning_rate": 0.00026994711567685854,
      "loss": 3.2459,
      "step": 3300
    },
    {
      "epoch": 0.10333718314996049,
      "grad_norm": 3.771409034729004,
      "learning_rate": 0.00026903531700200596,
      "loss": 3.2523,
      "step": 3400
    },
    {
      "epoch": 0.1063765120661358,
      "grad_norm": 1.9448480606079102,
      "learning_rate": 0.00026812351832715333,
      "loss": 3.1379,
      "step": 3500
    },
    {
      "epoch": 0.10941584098231111,
      "grad_norm": 2.0128731727600098,
      "learning_rate": 0.00026721171965230075,
      "loss": 3.183,
      "step": 3600
    },
    {
      "epoch": 0.11245516989848642,
      "grad_norm": 1.8369815349578857,
      "learning_rate": 0.0002662999209774482,
      "loss": 3.2543,
      "step": 3700
    },
    {
      "epoch": 0.11549449881466173,
      "grad_norm": 2.4352357387542725,
      "learning_rate": 0.00026538812230259554,
      "loss": 3.182,
      "step": 3800
    },
    {
      "epoch": 0.11853382773083704,
      "grad_norm": 1.7348523139953613,
      "learning_rate": 0.00026447632362774296,
      "loss": 3.1821,
      "step": 3900
    },
    {
      "epoch": 0.12157315664701233,
      "grad_norm": 2.0739800930023193,
      "learning_rate": 0.0002635645249528904,
      "loss": 3.1562,
      "step": 4000
    },
    {
      "epoch": 0.12461248556318764,
      "grad_norm": 1.8875492811203003,
      "learning_rate": 0.0002626527262780378,
      "loss": 3.2564,
      "step": 4100
    },
    {
      "epoch": 0.12765181447936297,
      "grad_norm": 2.571049451828003,
      "learning_rate": 0.0002617409276031852,
      "loss": 3.177,
      "step": 4200
    },
    {
      "epoch": 0.13069114339553828,
      "grad_norm": 1.9073927402496338,
      "learning_rate": 0.0002608291289283326,
      "loss": 3.1883,
      "step": 4300
    },
    {
      "epoch": 0.13373047231171356,
      "grad_norm": 2.0376265048980713,
      "learning_rate": 0.00025991733025348,
      "loss": 3.1346,
      "step": 4400
    },
    {
      "epoch": 0.13676980122788887,
      "grad_norm": 2.4873595237731934,
      "learning_rate": 0.0002590055315786274,
      "loss": 3.1721,
      "step": 4500
    },
    {
      "epoch": 0.13980913014406418,
      "grad_norm": 3.6129796504974365,
      "learning_rate": 0.0002580937329037748,
      "loss": 3.236,
      "step": 4600
    },
    {
      "epoch": 0.1428484590602395,
      "grad_norm": 1.7249304056167603,
      "learning_rate": 0.00025718193422892224,
      "loss": 3.1548,
      "step": 4700
    },
    {
      "epoch": 0.1458877879764148,
      "grad_norm": 2.191314697265625,
      "learning_rate": 0.0002562701355540696,
      "loss": 3.2119,
      "step": 4800
    },
    {
      "epoch": 0.1489271168925901,
      "grad_norm": 1.6258267164230347,
      "learning_rate": 0.00025535833687921703,
      "loss": 3.2593,
      "step": 4900
    },
    {
      "epoch": 0.15196644580876542,
      "grad_norm": 2.685241222381592,
      "learning_rate": 0.00025444653820436445,
      "loss": 3.2296,
      "step": 5000
    },
    {
      "epoch": 0.15500577472494073,
      "grad_norm": 2.131284713745117,
      "learning_rate": 0.0002535438575162604,
      "loss": 3.1809,
      "step": 5100
    },
    {
      "epoch": 0.15804510364111604,
      "grad_norm": 2.454035758972168,
      "learning_rate": 0.0002526320588414078,
      "loss": 3.1229,
      "step": 5200
    },
    {
      "epoch": 0.16108443255729135,
      "grad_norm": 1.8587404489517212,
      "learning_rate": 0.0002517202601665552,
      "loss": 3.1511,
      "step": 5300
    },
    {
      "epoch": 0.16412376147346666,
      "grad_norm": 2.1395912170410156,
      "learning_rate": 0.0002508084614917026,
      "loss": 3.2142,
      "step": 5400
    },
    {
      "epoch": 0.16716309038964197,
      "grad_norm": 2.416545867919922,
      "learning_rate": 0.00024989666281685,
      "loss": 3.189,
      "step": 5500
    },
    {
      "epoch": 0.17020241930581728,
      "grad_norm": 2.050344228744507,
      "learning_rate": 0.00024898486414199743,
      "loss": 3.2271,
      "step": 5600
    },
    {
      "epoch": 0.1732417482219926,
      "grad_norm": 2.229989528656006,
      "learning_rate": 0.0002480730654671448,
      "loss": 3.1458,
      "step": 5700
    },
    {
      "epoch": 0.1762810771381679,
      "grad_norm": 2.617154598236084,
      "learning_rate": 0.0002471612667922922,
      "loss": 3.1626,
      "step": 5800
    },
    {
      "epoch": 0.1793204060543432,
      "grad_norm": 2.3756656646728516,
      "learning_rate": 0.00024624946811743965,
      "loss": 3.109,
      "step": 5900
    },
    {
      "epoch": 0.18235973497051852,
      "grad_norm": 2.9510445594787598,
      "learning_rate": 0.00024533766944258707,
      "loss": 3.1429,
      "step": 6000
    },
    {
      "epoch": 0.1853990638866938,
      "grad_norm": 2.413909435272217,
      "learning_rate": 0.00024442587076773444,
      "loss": 3.1504,
      "step": 6100
    },
    {
      "epoch": 0.18843839280286911,
      "grad_norm": 2.3347978591918945,
      "learning_rate": 0.00024351407209288186,
      "loss": 3.2282,
      "step": 6200
    },
    {
      "epoch": 0.19147772171904442,
      "grad_norm": 1.9034502506256104,
      "learning_rate": 0.00024260227341802926,
      "loss": 3.1489,
      "step": 6300
    },
    {
      "epoch": 0.19451705063521973,
      "grad_norm": 1.8151103258132935,
      "learning_rate": 0.00024169047474317668,
      "loss": 3.1139,
      "step": 6400
    },
    {
      "epoch": 0.19755637955139504,
      "grad_norm": 2.275063991546631,
      "learning_rate": 0.00024077867606832408,
      "loss": 3.1645,
      "step": 6500
    },
    {
      "epoch": 0.20059570846757036,
      "grad_norm": 2.0795061588287354,
      "learning_rate": 0.0002398668773934715,
      "loss": 3.16,
      "step": 6600
    },
    {
      "epoch": 0.20363503738374567,
      "grad_norm": 2.6917340755462646,
      "learning_rate": 0.0002389550787186189,
      "loss": 3.1346,
      "step": 6700
    },
    {
      "epoch": 0.20667436629992098,
      "grad_norm": 2.2108359336853027,
      "learning_rate": 0.00023804328004376632,
      "loss": 3.1195,
      "step": 6800
    },
    {
      "epoch": 0.20971369521609629,
      "grad_norm": 1.8573535680770874,
      "learning_rate": 0.00023713148136891371,
      "loss": 3.1144,
      "step": 6900
    },
    {
      "epoch": 0.2127530241322716,
      "grad_norm": 1.996734619140625,
      "learning_rate": 0.0002362196826940611,
      "loss": 3.1441,
      "step": 7000
    },
    {
      "epoch": 0.2157923530484469,
      "grad_norm": 2.0464656352996826,
      "learning_rate": 0.00023530788401920853,
      "loss": 3.0802,
      "step": 7100
    },
    {
      "epoch": 0.21883168196462222,
      "grad_norm": 2.999598741531372,
      "learning_rate": 0.00023439608534435593,
      "loss": 3.0705,
      "step": 7200
    },
    {
      "epoch": 0.22187101088079753,
      "grad_norm": 1.5430551767349243,
      "learning_rate": 0.00023349340465625187,
      "loss": 3.1041,
      "step": 7300
    },
    {
      "epoch": 0.22491033979697284,
      "grad_norm": 1.6899081468582153,
      "learning_rate": 0.00023258160598139927,
      "loss": 3.0817,
      "step": 7400
    },
    {
      "epoch": 0.22794966871314815,
      "grad_norm": 1.7142858505249023,
      "learning_rate": 0.0002316698073065467,
      "loss": 3.0941,
      "step": 7500
    },
    {
      "epoch": 0.23098899762932346,
      "grad_norm": 2.047020673751831,
      "learning_rate": 0.0002307580086316941,
      "loss": 3.1143,
      "step": 7600
    },
    {
      "epoch": 0.23402832654549877,
      "grad_norm": 3.0403716564178467,
      "learning_rate": 0.00022984620995684149,
      "loss": 3.1637,
      "step": 7700
    },
    {
      "epoch": 0.23706765546167408,
      "grad_norm": 1.9731825590133667,
      "learning_rate": 0.0002289344112819889,
      "loss": 3.1051,
      "step": 7800
    },
    {
      "epoch": 0.24010698437784936,
      "grad_norm": 1.7515121698379517,
      "learning_rate": 0.0002280226126071363,
      "loss": 3.0454,
      "step": 7900
    },
    {
      "epoch": 0.24314631329402467,
      "grad_norm": 3.1440067291259766,
      "learning_rate": 0.00022711081393228373,
      "loss": 3.0641,
      "step": 8000
    },
    {
      "epoch": 0.24618564221019998,
      "grad_norm": 2.9251439571380615,
      "learning_rate": 0.00022619901525743112,
      "loss": 3.0844,
      "step": 8100
    },
    {
      "epoch": 0.2492249711263753,
      "grad_norm": 2.366231918334961,
      "learning_rate": 0.00022528721658257855,
      "loss": 3.0942,
      "step": 8200
    },
    {
      "epoch": 0.2522643000425506,
      "grad_norm": 1.8554459810256958,
      "learning_rate": 0.00022437541790772594,
      "loss": 3.0793,
      "step": 8300
    },
    {
      "epoch": 0.25530362895872594,
      "grad_norm": 2.9283907413482666,
      "learning_rate": 0.00022346361923287334,
      "loss": 3.1476,
      "step": 8400
    },
    {
      "epoch": 0.25834295787490125,
      "grad_norm": 3.780454635620117,
      "learning_rate": 0.00022255182055802076,
      "loss": 3.0191,
      "step": 8500
    },
    {
      "epoch": 0.26138228679107656,
      "grad_norm": 1.8501330614089966,
      "learning_rate": 0.00022164002188316816,
      "loss": 3.0513,
      "step": 8600
    },
    {
      "epoch": 0.2644216157072518,
      "grad_norm": 2.500214099884033,
      "learning_rate": 0.00022072822320831558,
      "loss": 3.077,
      "step": 8700
    },
    {
      "epoch": 0.2674609446234271,
      "grad_norm": 2.4921321868896484,
      "learning_rate": 0.00021981642453346297,
      "loss": 3.1143,
      "step": 8800
    },
    {
      "epoch": 0.27050027353960243,
      "grad_norm": 2.2052435874938965,
      "learning_rate": 0.00021890462585861042,
      "loss": 3.0585,
      "step": 8900
    },
    {
      "epoch": 0.27353960245577774,
      "grad_norm": 2.8996920585632324,
      "learning_rate": 0.00021799282718375782,
      "loss": 3.1578,
      "step": 9000
    },
    {
      "epoch": 0.27657893137195305,
      "grad_norm": 2.7665963172912598,
      "learning_rate": 0.00021708102850890524,
      "loss": 3.1164,
      "step": 9100
    },
    {
      "epoch": 0.27961826028812836,
      "grad_norm": 1.7046432495117188,
      "learning_rate": 0.00021616922983405264,
      "loss": 3.0684,
      "step": 9200
    },
    {
      "epoch": 0.28265758920430367,
      "grad_norm": 2.331331729888916,
      "learning_rate": 0.00021525743115920003,
      "loss": 3.1155,
      "step": 9300
    },
    {
      "epoch": 0.285696918120479,
      "grad_norm": 2.0208022594451904,
      "learning_rate": 0.00021434563248434746,
      "loss": 3.0851,
      "step": 9400
    },
    {
      "epoch": 0.2887362470366543,
      "grad_norm": 2.8701207637786865,
      "learning_rate": 0.00021343383380949485,
      "loss": 3.1147,
      "step": 9500
    },
    {
      "epoch": 0.2917755759528296,
      "grad_norm": 1.918276071548462,
      "learning_rate": 0.00021252203513464228,
      "loss": 3.0689,
      "step": 9600
    },
    {
      "epoch": 0.2948149048690049,
      "grad_norm": 2.3592519760131836,
      "learning_rate": 0.00021161023645978967,
      "loss": 3.051,
      "step": 9700
    },
    {
      "epoch": 0.2978542337851802,
      "grad_norm": 1.975197434425354,
      "learning_rate": 0.00021070755577168562,
      "loss": 3.077,
      "step": 9800
    },
    {
      "epoch": 0.30089356270135553,
      "grad_norm": 2.105546712875366,
      "learning_rate": 0.00020979575709683301,
      "loss": 3.1028,
      "step": 9900
    },
    {
      "epoch": 0.30393289161753084,
      "grad_norm": 1.782043695449829,
      "learning_rate": 0.00020888395842198044,
      "loss": 3.0952,
      "step": 10000
    },
    {
      "epoch": 0.30697222053370615,
      "grad_norm": 1.9156135320663452,
      "learning_rate": 0.00020797215974712783,
      "loss": 3.0295,
      "step": 10100
    },
    {
      "epoch": 0.31001154944988146,
      "grad_norm": 1.7703412771224976,
      "learning_rate": 0.00020706036107227523,
      "loss": 3.0978,
      "step": 10200
    },
    {
      "epoch": 0.3130508783660568,
      "grad_norm": 2.6625068187713623,
      "learning_rate": 0.00020614856239742265,
      "loss": 3.105,
      "step": 10300
    },
    {
      "epoch": 0.3160902072822321,
      "grad_norm": 1.9636876583099365,
      "learning_rate": 0.00020523676372257005,
      "loss": 3.062,
      "step": 10400
    },
    {
      "epoch": 0.3191295361984074,
      "grad_norm": 1.8468997478485107,
      "learning_rate": 0.00020432496504771747,
      "loss": 3.0006,
      "step": 10500
    },
    {
      "epoch": 0.3221688651145827,
      "grad_norm": 2.317237138748169,
      "learning_rate": 0.00020341316637286487,
      "loss": 3.0312,
      "step": 10600
    },
    {
      "epoch": 0.325208194030758,
      "grad_norm": 1.857956051826477,
      "learning_rate": 0.00020250136769801226,
      "loss": 3.0771,
      "step": 10700
    },
    {
      "epoch": 0.3282475229469333,
      "grad_norm": 1.6957241296768188,
      "learning_rate": 0.00020158956902315968,
      "loss": 3.0556,
      "step": 10800
    },
    {
      "epoch": 0.33128685186310863,
      "grad_norm": 2.2932541370391846,
      "learning_rate": 0.00020067777034830708,
      "loss": 3.0165,
      "step": 10900
    },
    {
      "epoch": 0.33432618077928394,
      "grad_norm": 2.96769380569458,
      "learning_rate": 0.0001997659716734545,
      "loss": 3.048,
      "step": 11000
    },
    {
      "epoch": 0.33736550969545925,
      "grad_norm": 1.9502419233322144,
      "learning_rate": 0.0001988541729986019,
      "loss": 3.0619,
      "step": 11100
    },
    {
      "epoch": 0.34040483861163456,
      "grad_norm": 2.0160093307495117,
      "learning_rate": 0.00019794237432374932,
      "loss": 3.1066,
      "step": 11200
    },
    {
      "epoch": 0.3434441675278099,
      "grad_norm": 2.020932912826538,
      "learning_rate": 0.00019703057564889672,
      "loss": 3.1332,
      "step": 11300
    },
    {
      "epoch": 0.3464834964439852,
      "grad_norm": 1.5475890636444092,
      "learning_rate": 0.0001961187769740441,
      "loss": 3.0509,
      "step": 11400
    },
    {
      "epoch": 0.3495228253601605,
      "grad_norm": 2.926316022872925,
      "learning_rate": 0.00019520697829919154,
      "loss": 3.0354,
      "step": 11500
    },
    {
      "epoch": 0.3525621542763358,
      "grad_norm": 1.7563420534133911,
      "learning_rate": 0.00019429517962433893,
      "loss": 3.0327,
      "step": 11600
    },
    {
      "epoch": 0.3556014831925111,
      "grad_norm": 2.5615031719207764,
      "learning_rate": 0.00019338338094948635,
      "loss": 3.0859,
      "step": 11700
    },
    {
      "epoch": 0.3586408121086864,
      "grad_norm": 1.800769329071045,
      "learning_rate": 0.00019247158227463375,
      "loss": 3.0852,
      "step": 11800
    },
    {
      "epoch": 0.36168014102486173,
      "grad_norm": 1.974291205406189,
      "learning_rate": 0.00019155978359978115,
      "loss": 3.0542,
      "step": 11900
    },
    {
      "epoch": 0.36471946994103704,
      "grad_norm": 2.3398451805114746,
      "learning_rate": 0.00019064798492492857,
      "loss": 2.9992,
      "step": 12000
    },
    {
      "epoch": 0.36775879885721235,
      "grad_norm": 2.1307730674743652,
      "learning_rate": 0.00018974530423682452,
      "loss": 3.057,
      "step": 12100
    },
    {
      "epoch": 0.3707981277733876,
      "grad_norm": 3.0666043758392334,
      "learning_rate": 0.0001888335055619719,
      "loss": 3.0407,
      "step": 12200
    },
    {
      "epoch": 0.3738374566895629,
      "grad_norm": 2.177485942840576,
      "learning_rate": 0.0001879217068871193,
      "loss": 2.98,
      "step": 12300
    },
    {
      "epoch": 0.37687678560573823,
      "grad_norm": 2.276121139526367,
      "learning_rate": 0.00018700990821226673,
      "loss": 3.0836,
      "step": 12400
    },
    {
      "epoch": 0.37991611452191354,
      "grad_norm": 2.173987865447998,
      "learning_rate": 0.00018609810953741413,
      "loss": 3.1119,
      "step": 12500
    },
    {
      "epoch": 0.38295544343808885,
      "grad_norm": 2.380406618118286,
      "learning_rate": 0.00018518631086256155,
      "loss": 3.0675,
      "step": 12600
    },
    {
      "epoch": 0.38599477235426416,
      "grad_norm": 2.146352529525757,
      "learning_rate": 0.00018427451218770894,
      "loss": 3.0573,
      "step": 12700
    },
    {
      "epoch": 0.38903410127043947,
      "grad_norm": 2.114011287689209,
      "learning_rate": 0.00018336271351285634,
      "loss": 3.1062,
      "step": 12800
    },
    {
      "epoch": 0.3920734301866148,
      "grad_norm": 2.170952558517456,
      "learning_rate": 0.00018245091483800376,
      "loss": 3.1018,
      "step": 12900
    },
    {
      "epoch": 0.3951127591027901,
      "grad_norm": 3.0650060176849365,
      "learning_rate": 0.00018153911616315116,
      "loss": 3.0409,
      "step": 13000
    },
    {
      "epoch": 0.3981520880189654,
      "grad_norm": 2.412057638168335,
      "learning_rate": 0.00018062731748829858,
      "loss": 3.0633,
      "step": 13100
    },
    {
      "epoch": 0.4011914169351407,
      "grad_norm": 1.7406843900680542,
      "learning_rate": 0.00017971551881344598,
      "loss": 3.0514,
      "step": 13200
    },
    {
      "epoch": 0.404230745851316,
      "grad_norm": 2.0400876998901367,
      "learning_rate": 0.0001788037201385934,
      "loss": 3.0641,
      "step": 13300
    },
    {
      "epoch": 0.40727007476749133,
      "grad_norm": 2.6430137157440186,
      "learning_rate": 0.0001778919214637408,
      "loss": 3.0741,
      "step": 13400
    },
    {
      "epoch": 0.41030940368366664,
      "grad_norm": 2.1122148036956787,
      "learning_rate": 0.0001769801227888882,
      "loss": 3.0227,
      "step": 13500
    },
    {
      "epoch": 0.41334873259984195,
      "grad_norm": 2.3490920066833496,
      "learning_rate": 0.00017606832411403561,
      "loss": 3.0428,
      "step": 13600
    },
    {
      "epoch": 0.41638806151601726,
      "grad_norm": 1.9365488290786743,
      "learning_rate": 0.000175156525439183,
      "loss": 3.0181,
      "step": 13700
    },
    {
      "epoch": 0.41942739043219257,
      "grad_norm": 1.9820556640625,
      "learning_rate": 0.00017424472676433043,
      "loss": 3.1565,
      "step": 13800
    },
    {
      "epoch": 0.4224667193483679,
      "grad_norm": 4.454973220825195,
      "learning_rate": 0.00017333292808947783,
      "loss": 3.0221,
      "step": 13900
    },
    {
      "epoch": 0.4255060482645432,
      "grad_norm": 2.4373741149902344,
      "learning_rate": 0.00017242112941462522,
      "loss": 2.9758,
      "step": 14000
    },
    {
      "epoch": 0.4285453771807185,
      "grad_norm": 2.487752914428711,
      "learning_rate": 0.00017150933073977265,
      "loss": 3.0774,
      "step": 14100
    },
    {
      "epoch": 0.4315847060968938,
      "grad_norm": 2.3046865463256836,
      "learning_rate": 0.0001706066500516686,
      "loss": 3.0196,
      "step": 14200
    },
    {
      "epoch": 0.4346240350130691,
      "grad_norm": 1.8235952854156494,
      "learning_rate": 0.000169694851376816,
      "loss": 3.036,
      "step": 14300
    },
    {
      "epoch": 0.43766336392924443,
      "grad_norm": 1.8942314386367798,
      "learning_rate": 0.00016878305270196339,
      "loss": 2.9585,
      "step": 14400
    },
    {
      "epoch": 0.44070269284541974,
      "grad_norm": 2.266554117202759,
      "learning_rate": 0.0001678712540271108,
      "loss": 3.0507,
      "step": 14500
    },
    {
      "epoch": 0.44374202176159505,
      "grad_norm": 1.9891014099121094,
      "learning_rate": 0.0001669594553522582,
      "loss": 3.046,
      "step": 14600
    },
    {
      "epoch": 0.44678135067777036,
      "grad_norm": 1.7247581481933594,
      "learning_rate": 0.00016604765667740563,
      "loss": 3.0499,
      "step": 14700
    },
    {
      "epoch": 0.44982067959394567,
      "grad_norm": 2.1637115478515625,
      "learning_rate": 0.00016513585800255302,
      "loss": 3.0816,
      "step": 14800
    },
    {
      "epoch": 0.452860008510121,
      "grad_norm": 2.1516220569610596,
      "learning_rate": 0.00016422405932770042,
      "loss": 3.0304,
      "step": 14900
    },
    {
      "epoch": 0.4558993374262963,
      "grad_norm": 2.310243606567383,
      "learning_rate": 0.00016331226065284784,
      "loss": 3.0315,
      "step": 15000
    },
    {
      "epoch": 0.4589386663424716,
      "grad_norm": 1.786468267440796,
      "learning_rate": 0.00016240046197799524,
      "loss": 3.045,
      "step": 15100
    },
    {
      "epoch": 0.4619779952586469,
      "grad_norm": 1.7597970962524414,
      "learning_rate": 0.00016148866330314266,
      "loss": 3.0232,
      "step": 15200
    },
    {
      "epoch": 0.4650173241748222,
      "grad_norm": 2.308457374572754,
      "learning_rate": 0.00016057686462829006,
      "loss": 3.0234,
      "step": 15300
    },
    {
      "epoch": 0.46805665309099753,
      "grad_norm": 1.697949767112732,
      "learning_rate": 0.00015966506595343748,
      "loss": 3.0624,
      "step": 15400
    },
    {
      "epoch": 0.47109598200717284,
      "grad_norm": 2.7297604084014893,
      "learning_rate": 0.00015875326727858487,
      "loss": 3.0471,
      "step": 15500
    },
    {
      "epoch": 0.47413531092334815,
      "grad_norm": 1.8569551706314087,
      "learning_rate": 0.00015784146860373227,
      "loss": 3.0956,
      "step": 15600
    },
    {
      "epoch": 0.4771746398395234,
      "grad_norm": 2.032346725463867,
      "learning_rate": 0.0001569296699288797,
      "loss": 3.0244,
      "step": 15700
    },
    {
      "epoch": 0.4802139687556987,
      "grad_norm": 2.552644968032837,
      "learning_rate": 0.0001560178712540271,
      "loss": 3.1465,
      "step": 15800
    },
    {
      "epoch": 0.483253297671874,
      "grad_norm": 2.085529327392578,
      "learning_rate": 0.0001551060725791745,
      "loss": 3.0251,
      "step": 15900
    },
    {
      "epoch": 0.48629262658804934,
      "grad_norm": 1.9058983325958252,
      "learning_rate": 0.0001541942739043219,
      "loss": 3.0788,
      "step": 16000
    },
    {
      "epoch": 0.48933195550422465,
      "grad_norm": 2.4610214233398438,
      "learning_rate": 0.0001532824752294693,
      "loss": 3.048,
      "step": 16100
    },
    {
      "epoch": 0.49237128442039996,
      "grad_norm": 1.9480994939804077,
      "learning_rate": 0.00015237067655461673,
      "loss": 3.0656,
      "step": 16200
    },
    {
      "epoch": 0.49541061333657527,
      "grad_norm": 2.1114330291748047,
      "learning_rate": 0.00015145887787976412,
      "loss": 3.0001,
      "step": 16300
    },
    {
      "epoch": 0.4984499422527506,
      "grad_norm": 1.87136971950531,
      "learning_rate": 0.00015054707920491154,
      "loss": 2.9693,
      "step": 16400
    },
    {
      "epoch": 0.5014892711689259,
      "grad_norm": 2.7683475017547607,
      "learning_rate": 0.00014963528053005894,
      "loss": 3.0534,
      "step": 16500
    },
    {
      "epoch": 0.5045286000851013,
      "grad_norm": 2.026268720626831,
      "learning_rate": 0.00014872348185520636,
      "loss": 3.0353,
      "step": 16600
    },
    {
      "epoch": 0.5075679290012766,
      "grad_norm": 2.4581689834594727,
      "learning_rate": 0.00014781168318035376,
      "loss": 3.0031,
      "step": 16700
    },
    {
      "epoch": 0.5106072579174519,
      "grad_norm": 1.7700567245483398,
      "learning_rate": 0.00014689988450550115,
      "loss": 3.033,
      "step": 16800
    },
    {
      "epoch": 0.5136465868336272,
      "grad_norm": 1.6025229692459106,
      "learning_rate": 0.00014598808583064858,
      "loss": 3.0456,
      "step": 16900
    },
    {
      "epoch": 0.5166859157498025,
      "grad_norm": 2.111722469329834,
      "learning_rate": 0.000145076287155796,
      "loss": 3.0685,
      "step": 17000
    },
    {
      "epoch": 0.5197252446659778,
      "grad_norm": 2.1854248046875,
      "learning_rate": 0.0001441644884809434,
      "loss": 3.07,
      "step": 17100
    },
    {
      "epoch": 0.5227645735821531,
      "grad_norm": 1.90630304813385,
      "learning_rate": 0.00014325268980609082,
      "loss": 2.9923,
      "step": 17200
    },
    {
      "epoch": 0.5258039024983284,
      "grad_norm": 3.6640710830688477,
      "learning_rate": 0.00014234089113123821,
      "loss": 3.013,
      "step": 17300
    },
    {
      "epoch": 0.5288432314145036,
      "grad_norm": 2.2062084674835205,
      "learning_rate": 0.0001414290924563856,
      "loss": 3.0414,
      "step": 17400
    },
    {
      "epoch": 0.5318825603306789,
      "grad_norm": 1.9529730081558228,
      "learning_rate": 0.00014052641176828156,
      "loss": 3.0004,
      "step": 17500
    },
    {
      "epoch": 0.5349218892468542,
      "grad_norm": 2.1293246746063232,
      "learning_rate": 0.00013961461309342895,
      "loss": 2.9783,
      "step": 17600
    },
    {
      "epoch": 0.5379612181630296,
      "grad_norm": 1.8606489896774292,
      "learning_rate": 0.00013870281441857635,
      "loss": 3.06,
      "step": 17700
    },
    {
      "epoch": 0.5410005470792049,
      "grad_norm": 1.841460943222046,
      "learning_rate": 0.00013779101574372377,
      "loss": 3.0611,
      "step": 17800
    },
    {
      "epoch": 0.5440398759953802,
      "grad_norm": 1.829412579536438,
      "learning_rate": 0.0001368792170688712,
      "loss": 2.9425,
      "step": 17900
    },
    {
      "epoch": 0.5470792049115555,
      "grad_norm": 2.3590087890625,
      "learning_rate": 0.0001359674183940186,
      "loss": 3.0397,
      "step": 18000
    },
    {
      "epoch": 0.5501185338277308,
      "grad_norm": 2.1018638610839844,
      "learning_rate": 0.000135055619719166,
      "loss": 3.0133,
      "step": 18100
    },
    {
      "epoch": 0.5531578627439061,
      "grad_norm": 2.243907928466797,
      "learning_rate": 0.0001341438210443134,
      "loss": 3.0158,
      "step": 18200
    },
    {
      "epoch": 0.5561971916600814,
      "grad_norm": 2.045025110244751,
      "learning_rate": 0.0001332320223694608,
      "loss": 2.9606,
      "step": 18300
    },
    {
      "epoch": 0.5592365205762567,
      "grad_norm": 1.6852754354476929,
      "learning_rate": 0.00013232022369460823,
      "loss": 3.0025,
      "step": 18400
    },
    {
      "epoch": 0.562275849492432,
      "grad_norm": 2.420715570449829,
      "learning_rate": 0.00013140842501975562,
      "loss": 3.1118,
      "step": 18500
    },
    {
      "epoch": 0.5653151784086073,
      "grad_norm": 1.7678309679031372,
      "learning_rate": 0.00013049662634490305,
      "loss": 3.0109,
      "step": 18600
    },
    {
      "epoch": 0.5683545073247827,
      "grad_norm": 1.6499834060668945,
      "learning_rate": 0.00012958482767005044,
      "loss": 3.0248,
      "step": 18700
    },
    {
      "epoch": 0.571393836240958,
      "grad_norm": 2.051882266998291,
      "learning_rate": 0.00012867302899519786,
      "loss": 2.9954,
      "step": 18800
    },
    {
      "epoch": 0.5744331651571333,
      "grad_norm": 2.3916985988616943,
      "learning_rate": 0.00012776123032034526,
      "loss": 2.9574,
      "step": 18900
    },
    {
      "epoch": 0.5774724940733086,
      "grad_norm": 2.3312277793884277,
      "learning_rate": 0.00012684943164549266,
      "loss": 2.971,
      "step": 19000
    },
    {
      "epoch": 0.5805118229894839,
      "grad_norm": 1.6790651082992554,
      "learning_rate": 0.00012593763297064008,
      "loss": 3.0378,
      "step": 19100
    },
    {
      "epoch": 0.5835511519056592,
      "grad_norm": 3.0257997512817383,
      "learning_rate": 0.00012502583429578747,
      "loss": 2.9009,
      "step": 19200
    },
    {
      "epoch": 0.5865904808218345,
      "grad_norm": 1.8765368461608887,
      "learning_rate": 0.0001241140356209349,
      "loss": 2.9704,
      "step": 19300
    },
    {
      "epoch": 0.5896298097380098,
      "grad_norm": 2.2029190063476562,
      "learning_rate": 0.0001232022369460823,
      "loss": 3.0451,
      "step": 19400
    },
    {
      "epoch": 0.5926691386541851,
      "grad_norm": 2.1807150840759277,
      "learning_rate": 0.0001222904382712297,
      "loss": 3.0254,
      "step": 19500
    },
    {
      "epoch": 0.5957084675703604,
      "grad_norm": 2.0975229740142822,
      "learning_rate": 0.00012137863959637711,
      "loss": 2.9888,
      "step": 19600
    },
    {
      "epoch": 0.5987477964865358,
      "grad_norm": 1.9337509870529175,
      "learning_rate": 0.00012046684092152452,
      "loss": 3.1106,
      "step": 19700
    },
    {
      "epoch": 0.6017871254027111,
      "grad_norm": 1.704591989517212,
      "learning_rate": 0.00011955504224667192,
      "loss": 3.0388,
      "step": 19800
    },
    {
      "epoch": 0.6048264543188864,
      "grad_norm": 1.7890069484710693,
      "learning_rate": 0.00011864324357181933,
      "loss": 2.9569,
      "step": 19900
    },
    {
      "epoch": 0.6078657832350617,
      "grad_norm": 2.151437282562256,
      "learning_rate": 0.00011774056288371527,
      "loss": 3.0267,
      "step": 20000
    },
    {
      "epoch": 0.610905112151237,
      "grad_norm": 2.19499135017395,
      "learning_rate": 0.00011682876420886267,
      "loss": 2.9734,
      "step": 20100
    },
    {
      "epoch": 0.6139444410674123,
      "grad_norm": 3.00903582572937,
      "learning_rate": 0.00011591696553401008,
      "loss": 3.033,
      "step": 20200
    },
    {
      "epoch": 0.6169837699835876,
      "grad_norm": 2.2725000381469727,
      "learning_rate": 0.00011500516685915749,
      "loss": 2.9856,
      "step": 20300
    },
    {
      "epoch": 0.6200230988997629,
      "grad_norm": 2.136354923248291,
      "learning_rate": 0.0001140933681843049,
      "loss": 2.9678,
      "step": 20400
    },
    {
      "epoch": 0.6230624278159382,
      "grad_norm": 2.3436119556427,
      "learning_rate": 0.0001131815695094523,
      "loss": 2.9847,
      "step": 20500
    },
    {
      "epoch": 0.6261017567321135,
      "grad_norm": 2.547142744064331,
      "learning_rate": 0.00011226977083459971,
      "loss": 2.997,
      "step": 20600
    },
    {
      "epoch": 0.6291410856482889,
      "grad_norm": 2.111064910888672,
      "learning_rate": 0.00011135797215974711,
      "loss": 2.9869,
      "step": 20700
    },
    {
      "epoch": 0.6321804145644642,
      "grad_norm": 1.7844642400741577,
      "learning_rate": 0.00011044617348489452,
      "loss": 2.9866,
      "step": 20800
    },
    {
      "epoch": 0.6352197434806395,
      "grad_norm": 2.821089506149292,
      "learning_rate": 0.00010953437481004193,
      "loss": 3.0408,
      "step": 20900
    },
    {
      "epoch": 0.6382590723968148,
      "grad_norm": 1.5165091753005981,
      "learning_rate": 0.00010862257613518934,
      "loss": 2.9998,
      "step": 21000
    },
    {
      "epoch": 0.6412984013129901,
      "grad_norm": 2.0410242080688477,
      "learning_rate": 0.00010771077746033675,
      "loss": 2.9877,
      "step": 21100
    },
    {
      "epoch": 0.6443377302291654,
      "grad_norm": 2.1037440299987793,
      "learning_rate": 0.00010679897878548416,
      "loss": 2.9877,
      "step": 21200
    },
    {
      "epoch": 0.6473770591453407,
      "grad_norm": 2.4683432579040527,
      "learning_rate": 0.00010588718011063155,
      "loss": 2.9769,
      "step": 21300
    },
    {
      "epoch": 0.650416388061516,
      "grad_norm": 1.6157268285751343,
      "learning_rate": 0.00010497538143577896,
      "loss": 3.0235,
      "step": 21400
    },
    {
      "epoch": 0.6534557169776913,
      "grad_norm": 2.4336698055267334,
      "learning_rate": 0.00010406358276092637,
      "loss": 2.9926,
      "step": 21500
    },
    {
      "epoch": 0.6564950458938666,
      "grad_norm": 2.1598763465881348,
      "learning_rate": 0.00010315178408607378,
      "loss": 3.0562,
      "step": 21600
    },
    {
      "epoch": 0.659534374810042,
      "grad_norm": 1.9449254274368286,
      "learning_rate": 0.00010223998541122119,
      "loss": 3.0061,
      "step": 21700
    },
    {
      "epoch": 0.6625737037262173,
      "grad_norm": 2.8388872146606445,
      "learning_rate": 0.0001013281867363686,
      "loss": 3.0351,
      "step": 21800
    },
    {
      "epoch": 0.6656130326423926,
      "grad_norm": 1.762407898902893,
      "learning_rate": 0.000100416388061516,
      "loss": 2.9906,
      "step": 21900
    },
    {
      "epoch": 0.6686523615585679,
      "grad_norm": 1.927613377571106,
      "learning_rate": 9.95045893866634e-05,
      "loss": 2.9747,
      "step": 22000
    },
    {
      "epoch": 0.6716916904747432,
      "grad_norm": 2.2371342182159424,
      "learning_rate": 9.860190869855935e-05,
      "loss": 2.9514,
      "step": 22100
    },
    {
      "epoch": 0.6747310193909185,
      "grad_norm": 1.9442956447601318,
      "learning_rate": 9.769011002370675e-05,
      "loss": 3.0766,
      "step": 22200
    },
    {
      "epoch": 0.6777703483070938,
      "grad_norm": 2.4034485816955566,
      "learning_rate": 9.677831134885416e-05,
      "loss": 2.9803,
      "step": 22300
    },
    {
      "epoch": 0.6808096772232691,
      "grad_norm": 2.223464250564575,
      "learning_rate": 9.586651267400157e-05,
      "loss": 2.9939,
      "step": 22400
    },
    {
      "epoch": 0.6838490061394444,
      "grad_norm": 2.293865919113159,
      "learning_rate": 9.495471399914897e-05,
      "loss": 2.9618,
      "step": 22500
    },
    {
      "epoch": 0.6868883350556197,
      "grad_norm": 2.1255693435668945,
      "learning_rate": 9.404291532429638e-05,
      "loss": 3.0239,
      "step": 22600
    },
    {
      "epoch": 0.6899276639717951,
      "grad_norm": 2.1940062046051025,
      "learning_rate": 9.31311166494438e-05,
      "loss": 2.9656,
      "step": 22700
    },
    {
      "epoch": 0.6929669928879704,
      "grad_norm": 1.5169764757156372,
      "learning_rate": 9.221931797459119e-05,
      "loss": 2.9651,
      "step": 22800
    },
    {
      "epoch": 0.6960063218041457,
      "grad_norm": 3.5414390563964844,
      "learning_rate": 9.13075192997386e-05,
      "loss": 3.0424,
      "step": 22900
    },
    {
      "epoch": 0.699045650720321,
      "grad_norm": 1.6908752918243408,
      "learning_rate": 9.039572062488602e-05,
      "loss": 2.9195,
      "step": 23000
    },
    {
      "epoch": 0.7020849796364963,
      "grad_norm": 2.2720553874969482,
      "learning_rate": 8.948392195003343e-05,
      "loss": 2.9746,
      "step": 23100
    },
    {
      "epoch": 0.7051243085526716,
      "grad_norm": 2.4722845554351807,
      "learning_rate": 8.857212327518084e-05,
      "loss": 3.0062,
      "step": 23200
    },
    {
      "epoch": 0.7081636374688469,
      "grad_norm": 2.010859727859497,
      "learning_rate": 8.766032460032825e-05,
      "loss": 2.9823,
      "step": 23300
    },
    {
      "epoch": 0.7112029663850222,
      "grad_norm": 1.6117374897003174,
      "learning_rate": 8.674852592547566e-05,
      "loss": 2.9877,
      "step": 23400
    },
    {
      "epoch": 0.7142422953011975,
      "grad_norm": 2.2702529430389404,
      "learning_rate": 8.583672725062305e-05,
      "loss": 3.039,
      "step": 23500
    },
    {
      "epoch": 0.7172816242173728,
      "grad_norm": 2.3571035861968994,
      "learning_rate": 8.492492857577046e-05,
      "loss": 2.9305,
      "step": 23600
    },
    {
      "epoch": 0.7203209531335482,
      "grad_norm": 2.158968210220337,
      "learning_rate": 8.401312990091787e-05,
      "loss": 3.0083,
      "step": 23700
    },
    {
      "epoch": 0.7233602820497235,
      "grad_norm": 1.8714350461959839,
      "learning_rate": 8.310133122606528e-05,
      "loss": 2.9867,
      "step": 23800
    },
    {
      "epoch": 0.7263996109658988,
      "grad_norm": 1.70780348777771,
      "learning_rate": 8.218953255121269e-05,
      "loss": 2.9855,
      "step": 23900
    },
    {
      "epoch": 0.7294389398820741,
      "grad_norm": 3.7068331241607666,
      "learning_rate": 8.12777338763601e-05,
      "loss": 2.9405,
      "step": 24000
    },
    {
      "epoch": 0.7324782687982494,
      "grad_norm": 2.225827217102051,
      "learning_rate": 8.03659352015075e-05,
      "loss": 2.9777,
      "step": 24100
    },
    {
      "epoch": 0.7355175977144247,
      "grad_norm": 2.1410675048828125,
      "learning_rate": 7.94541365266549e-05,
      "loss": 2.9993,
      "step": 24200
    },
    {
      "epoch": 0.7385569266305999,
      "grad_norm": 2.4255661964416504,
      "learning_rate": 7.854233785180232e-05,
      "loss": 2.9571,
      "step": 24300
    },
    {
      "epoch": 0.7415962555467752,
      "grad_norm": 1.637894630432129,
      "learning_rate": 7.763053917694972e-05,
      "loss": 3.0063,
      "step": 24400
    },
    {
      "epoch": 0.7446355844629505,
      "grad_norm": 1.8706735372543335,
      "learning_rate": 7.671874050209713e-05,
      "loss": 2.925,
      "step": 24500
    },
    {
      "epoch": 0.7476749133791258,
      "grad_norm": 2.176192283630371,
      "learning_rate": 7.580694182724454e-05,
      "loss": 2.9296,
      "step": 24600
    },
    {
      "epoch": 0.7507142422953011,
      "grad_norm": 1.467140555381775,
      "learning_rate": 7.489514315239194e-05,
      "loss": 2.9817,
      "step": 24700
    },
    {
      "epoch": 0.7537535712114765,
      "grad_norm": 1.7637982368469238,
      "learning_rate": 7.398334447753935e-05,
      "loss": 2.9563,
      "step": 24800
    },
    {
      "epoch": 0.7567929001276518,
      "grad_norm": 2.03731369972229,
      "learning_rate": 7.30806637894353e-05,
      "loss": 2.9416,
      "step": 24900
    },
    {
      "epoch": 0.7598322290438271,
      "grad_norm": 2.0439677238464355,
      "learning_rate": 7.216886511458269e-05,
      "loss": 3.0184,
      "step": 25000
    },
    {
      "epoch": 0.7628715579600024,
      "grad_norm": 2.3674304485321045,
      "learning_rate": 7.12570664397301e-05,
      "loss": 2.9581,
      "step": 25100
    },
    {
      "epoch": 0.7659108868761777,
      "grad_norm": 2.0665526390075684,
      "learning_rate": 7.034526776487751e-05,
      "loss": 2.9792,
      "step": 25200
    },
    {
      "epoch": 0.768950215792353,
      "grad_norm": 2.1862759590148926,
      "learning_rate": 6.943346909002492e-05,
      "loss": 2.9538,
      "step": 25300
    },
    {
      "epoch": 0.7719895447085283,
      "grad_norm": 1.8172407150268555,
      "learning_rate": 6.852167041517233e-05,
      "loss": 3.0237,
      "step": 25400
    },
    {
      "epoch": 0.7750288736247036,
      "grad_norm": 2.061095952987671,
      "learning_rate": 6.760987174031974e-05,
      "loss": 2.9892,
      "step": 25500
    },
    {
      "epoch": 0.7780682025408789,
      "grad_norm": 1.6649913787841797,
      "learning_rate": 6.669807306546713e-05,
      "loss": 2.9878,
      "step": 25600
    },
    {
      "epoch": 0.7811075314570542,
      "grad_norm": 2.6478335857391357,
      "learning_rate": 6.578627439061454e-05,
      "loss": 2.9481,
      "step": 25700
    },
    {
      "epoch": 0.7841468603732296,
      "grad_norm": 2.0931854248046875,
      "learning_rate": 6.487447571576195e-05,
      "loss": 2.9929,
      "step": 25800
    },
    {
      "epoch": 0.7871861892894049,
      "grad_norm": 2.680525064468384,
      "learning_rate": 6.396267704090936e-05,
      "loss": 2.9709,
      "step": 25900
    },
    {
      "epoch": 0.7902255182055802,
      "grad_norm": 2.5268044471740723,
      "learning_rate": 6.305087836605677e-05,
      "loss": 2.9823,
      "step": 26000
    },
    {
      "epoch": 0.7932648471217555,
      "grad_norm": 2.7035861015319824,
      "learning_rate": 6.213907969120418e-05,
      "loss": 3.007,
      "step": 26100
    },
    {
      "epoch": 0.7963041760379308,
      "grad_norm": 2.74444842338562,
      "learning_rate": 6.122728101635158e-05,
      "loss": 2.9774,
      "step": 26200
    },
    {
      "epoch": 0.7993435049541061,
      "grad_norm": 1.8153369426727295,
      "learning_rate": 6.031548234149899e-05,
      "loss": 3.005,
      "step": 26300
    },
    {
      "epoch": 0.8023828338702814,
      "grad_norm": 2.0842125415802,
      "learning_rate": 5.9403683666646394e-05,
      "loss": 3.0181,
      "step": 26400
    },
    {
      "epoch": 0.8054221627864567,
      "grad_norm": 1.5309678316116333,
      "learning_rate": 5.849188499179381e-05,
      "loss": 2.9587,
      "step": 26500
    },
    {
      "epoch": 0.808461491702632,
      "grad_norm": 2.795166492462158,
      "learning_rate": 5.758008631694122e-05,
      "loss": 2.9508,
      "step": 26600
    },
    {
      "epoch": 0.8115008206188074,
      "grad_norm": 1.787152886390686,
      "learning_rate": 5.666828764208863e-05,
      "loss": 2.9853,
      "step": 26700
    },
    {
      "epoch": 0.8145401495349827,
      "grad_norm": 2.1386029720306396,
      "learning_rate": 5.575648896723603e-05,
      "loss": 2.919,
      "step": 26800
    },
    {
      "epoch": 0.817579478451158,
      "grad_norm": 2.4670774936676025,
      "learning_rate": 5.4853808279131964e-05,
      "loss": 2.9017,
      "step": 26900
    },
    {
      "epoch": 0.8206188073673333,
      "grad_norm": 2.1102612018585205,
      "learning_rate": 5.394200960427937e-05,
      "loss": 2.9504,
      "step": 27000
    },
    {
      "epoch": 0.8236581362835086,
      "grad_norm": 3.5187644958496094,
      "learning_rate": 5.3030210929426776e-05,
      "loss": 2.9839,
      "step": 27100
    },
    {
      "epoch": 0.8266974651996839,
      "grad_norm": 1.72214937210083,
      "learning_rate": 5.2118412254574185e-05,
      "loss": 2.9371,
      "step": 27200
    },
    {
      "epoch": 0.8297367941158592,
      "grad_norm": 1.667794942855835,
      "learning_rate": 5.120661357972159e-05,
      "loss": 2.9633,
      "step": 27300
    },
    {
      "epoch": 0.8327761230320345,
      "grad_norm": 1.8028227090835571,
      "learning_rate": 5.0294814904869004e-05,
      "loss": 2.9703,
      "step": 27400
    },
    {
      "epoch": 0.8358154519482098,
      "grad_norm": 2.462608814239502,
      "learning_rate": 4.938301623001641e-05,
      "loss": 2.9935,
      "step": 27500
    },
    {
      "epoch": 0.8388547808643851,
      "grad_norm": 1.7139655351638794,
      "learning_rate": 4.8471217555163816e-05,
      "loss": 2.9933,
      "step": 27600
    },
    {
      "epoch": 0.8418941097805605,
      "grad_norm": 2.4080276489257812,
      "learning_rate": 4.7559418880311225e-05,
      "loss": 2.9946,
      "step": 27700
    },
    {
      "epoch": 0.8449334386967358,
      "grad_norm": 2.6419897079467773,
      "learning_rate": 4.6647620205458634e-05,
      "loss": 2.9646,
      "step": 27800
    },
    {
      "epoch": 0.8479727676129111,
      "grad_norm": 2.068185567855835,
      "learning_rate": 4.573582153060604e-05,
      "loss": 2.9881,
      "step": 27900
    },
    {
      "epoch": 0.8510120965290864,
      "grad_norm": 2.063214063644409,
      "learning_rate": 4.4824022855753446e-05,
      "loss": 2.9529,
      "step": 28000
    },
    {
      "epoch": 0.8540514254452617,
      "grad_norm": 2.968719482421875,
      "learning_rate": 4.3912224180900855e-05,
      "loss": 3.0145,
      "step": 28100
    },
    {
      "epoch": 0.857090754361437,
      "grad_norm": 1.6320492029190063,
      "learning_rate": 4.300042550604826e-05,
      "loss": 3.0377,
      "step": 28200
    },
    {
      "epoch": 0.8601300832776123,
      "grad_norm": 1.9921902418136597,
      "learning_rate": 4.208862683119567e-05,
      "loss": 2.9502,
      "step": 28300
    },
    {
      "epoch": 0.8631694121937876,
      "grad_norm": 2.3281424045562744,
      "learning_rate": 4.1176828156343077e-05,
      "loss": 2.9472,
      "step": 28400
    },
    {
      "epoch": 0.8662087411099629,
      "grad_norm": 2.0012683868408203,
      "learning_rate": 4.026502948149048e-05,
      "loss": 2.945,
      "step": 28500
    },
    {
      "epoch": 0.8692480700261382,
      "grad_norm": 1.7853996753692627,
      "learning_rate": 3.935323080663789e-05,
      "loss": 2.9269,
      "step": 28600
    },
    {
      "epoch": 0.8722873989423136,
      "grad_norm": 1.8634778261184692,
      "learning_rate": 3.84414321317853e-05,
      "loss": 2.9588,
      "step": 28700
    },
    {
      "epoch": 0.8753267278584889,
      "grad_norm": 1.9599958658218384,
      "learning_rate": 3.75296334569327e-05,
      "loss": 2.8736,
      "step": 28800
    },
    {
      "epoch": 0.8783660567746642,
      "grad_norm": 2.216317653656006,
      "learning_rate": 3.6617834782080116e-05,
      "loss": 3.0167,
      "step": 28900
    },
    {
      "epoch": 0.8814053856908395,
      "grad_norm": 1.6571438312530518,
      "learning_rate": 3.570603610722752e-05,
      "loss": 2.9534,
      "step": 29000
    },
    {
      "epoch": 0.8844447146070148,
      "grad_norm": 1.9145045280456543,
      "learning_rate": 3.479423743237493e-05,
      "loss": 3.003,
      "step": 29100
    },
    {
      "epoch": 0.8874840435231901,
      "grad_norm": 1.8422688245773315,
      "learning_rate": 3.388243875752234e-05,
      "loss": 2.9354,
      "step": 29200
    },
    {
      "epoch": 0.8905233724393654,
      "grad_norm": 2.61214017868042,
      "learning_rate": 3.297064008266974e-05,
      "loss": 3.0023,
      "step": 29300
    },
    {
      "epoch": 0.8935627013555407,
      "grad_norm": 2.4004874229431152,
      "learning_rate": 3.205884140781715e-05,
      "loss": 2.9659,
      "step": 29400
    },
    {
      "epoch": 0.896602030271716,
      "grad_norm": 1.8167641162872314,
      "learning_rate": 3.114704273296456e-05,
      "loss": 2.9609,
      "step": 29500
    },
    {
      "epoch": 0.8996413591878913,
      "grad_norm": 1.899449110031128,
      "learning_rate": 3.0235244058111968e-05,
      "loss": 2.9094,
      "step": 29600
    },
    {
      "epoch": 0.9026806881040667,
      "grad_norm": 2.023261308670044,
      "learning_rate": 2.93325633700079e-05,
      "loss": 2.9903,
      "step": 29700
    },
    {
      "epoch": 0.905720017020242,
      "grad_norm": 1.6675407886505127,
      "learning_rate": 2.8420764695155307e-05,
      "loss": 3.0544,
      "step": 29800
    },
    {
      "epoch": 0.9087593459364173,
      "grad_norm": 1.9017051458358765,
      "learning_rate": 2.7508966020302716e-05,
      "loss": 2.9588,
      "step": 29900
    },
    {
      "epoch": 0.9117986748525926,
      "grad_norm": 2.154554605484009,
      "learning_rate": 2.6597167345450122e-05,
      "loss": 3.078,
      "step": 30000
    },
    {
      "epoch": 0.9148380037687679,
      "grad_norm": 2.877513885498047,
      "learning_rate": 2.5685368670597528e-05,
      "loss": 2.9495,
      "step": 30100
    },
    {
      "epoch": 0.9178773326849432,
      "grad_norm": 2.058241844177246,
      "learning_rate": 2.4773569995744937e-05,
      "loss": 2.9984,
      "step": 30200
    },
    {
      "epoch": 0.9209166616011185,
      "grad_norm": 2.754042387008667,
      "learning_rate": 2.3861771320892343e-05,
      "loss": 2.9199,
      "step": 30300
    },
    {
      "epoch": 0.9239559905172938,
      "grad_norm": 1.7480485439300537,
      "learning_rate": 2.294997264603975e-05,
      "loss": 2.9654,
      "step": 30400
    },
    {
      "epoch": 0.9269953194334691,
      "grad_norm": 1.9551665782928467,
      "learning_rate": 2.2038173971187162e-05,
      "loss": 2.9566,
      "step": 30500
    },
    {
      "epoch": 0.9300346483496444,
      "grad_norm": 3.171905279159546,
      "learning_rate": 2.1126375296334568e-05,
      "loss": 2.9959,
      "step": 30600
    },
    {
      "epoch": 0.9330739772658198,
      "grad_norm": 2.212548017501831,
      "learning_rate": 2.0214576621481977e-05,
      "loss": 3.0028,
      "step": 30700
    },
    {
      "epoch": 0.9361133061819951,
      "grad_norm": 1.900305151939392,
      "learning_rate": 1.9302777946629383e-05,
      "loss": 2.983,
      "step": 30800
    },
    {
      "epoch": 0.9391526350981704,
      "grad_norm": 1.8096812963485718,
      "learning_rate": 1.839097927177679e-05,
      "loss": 3.0243,
      "step": 30900
    },
    {
      "epoch": 0.9421919640143457,
      "grad_norm": 1.7214488983154297,
      "learning_rate": 1.7479180596924198e-05,
      "loss": 2.9681,
      "step": 31000
    },
    {
      "epoch": 0.945231292930521,
      "grad_norm": 3.7810263633728027,
      "learning_rate": 1.6567381922071604e-05,
      "loss": 2.9518,
      "step": 31100
    },
    {
      "epoch": 0.9482706218466963,
      "grad_norm": 2.141134023666382,
      "learning_rate": 1.5655583247219013e-05,
      "loss": 2.9356,
      "step": 31200
    },
    {
      "epoch": 0.9513099507628715,
      "grad_norm": 2.4292802810668945,
      "learning_rate": 1.4743784572366421e-05,
      "loss": 2.9491,
      "step": 31300
    },
    {
      "epoch": 0.9543492796790468,
      "grad_norm": 1.8560354709625244,
      "learning_rate": 1.3831985897513827e-05,
      "loss": 2.9366,
      "step": 31400
    },
    {
      "epoch": 0.9573886085952221,
      "grad_norm": 2.7687344551086426,
      "learning_rate": 1.2920187222661235e-05,
      "loss": 2.947,
      "step": 31500
    },
    {
      "epoch": 0.9604279375113974,
      "grad_norm": 1.7792850732803345,
      "learning_rate": 1.2008388547808644e-05,
      "loss": 2.9708,
      "step": 31600
    },
    {
      "epoch": 0.9634672664275727,
      "grad_norm": 2.2547054290771484,
      "learning_rate": 1.1096589872956051e-05,
      "loss": 2.8258,
      "step": 31700
    },
    {
      "epoch": 0.966506595343748,
      "grad_norm": 2.2746589183807373,
      "learning_rate": 1.0193909184851983e-05,
      "loss": 2.9341,
      "step": 31800
    },
    {
      "epoch": 0.9695459242599234,
      "grad_norm": 3.7519466876983643,
      "learning_rate": 9.28211050999939e-06,
      "loss": 2.9866,
      "step": 31900
    },
    {
      "epoch": 0.9725852531760987,
      "grad_norm": 2.721299886703491,
      "learning_rate": 8.370311835146798e-06,
      "loss": 2.9581,
      "step": 32000
    },
    {
      "epoch": 0.975624582092274,
      "grad_norm": 2.044010877609253,
      "learning_rate": 7.458513160294206e-06,
      "loss": 2.975,
      "step": 32100
    },
    {
      "epoch": 0.9786639110084493,
      "grad_norm": 1.7732709646224976,
      "learning_rate": 6.5467144854416145e-06,
      "loss": 3.0365,
      "step": 32200
    },
    {
      "epoch": 0.9817032399246246,
      "grad_norm": 3.38411283493042,
      "learning_rate": 5.634915810589021e-06,
      "loss": 2.947,
      "step": 32300
    },
    {
      "epoch": 0.9847425688407999,
      "grad_norm": 2.0531461238861084,
      "learning_rate": 4.72311713573643e-06,
      "loss": 2.9577,
      "step": 32400
    },
    {
      "epoch": 0.9877818977569752,
      "grad_norm": 2.2631640434265137,
      "learning_rate": 3.8113184608838364e-06,
      "loss": 2.9669,
      "step": 32500
    },
    {
      "epoch": 0.9908212266731505,
      "grad_norm": 1.7870131731033325,
      "learning_rate": 2.899519786031244e-06,
      "loss": 2.9645,
      "step": 32600
    },
    {
      "epoch": 0.9938605555893258,
      "grad_norm": 2.0399398803710938,
      "learning_rate": 1.9877211111786516e-06,
      "loss": 2.8787,
      "step": 32700
    },
    {
      "epoch": 0.9968998845055012,
      "grad_norm": 2.4287471771240234,
      "learning_rate": 1.0759224363260592e-06,
      "loss": 2.9227,
      "step": 32800
    },
    {
      "epoch": 0.9999392134216765,
      "grad_norm": 1.6014872789382935,
      "learning_rate": 1.6412376147346664e-07,
      "loss": 3.0071,
      "step": 32900
    }
  ],
  "logging_steps": 100,
  "max_steps": 32902,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4453015952031744.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
